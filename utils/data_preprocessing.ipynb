{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理工具\n",
    "## 异常值和缺失值处理\n",
    "\n",
    "本notebook用于处理dataset/B题因子库文件夹内的数据文件，支持多种异常值和缺失值处理方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据路径配置\n",
    "DATA_PATH = '../dataset/B题因子库'\n",
    "OUTPUT_PATH = '../dataset/B题因子库_processed'\n",
    "\n",
    "# 异常值处理方法\n",
    "OUTLIER_METHODS = {\n",
    "    'iqr': 'IQR方法',\n",
    "    'zscore': 'Z-score方法', \n",
    "    'isolation_forest': '孤立森林',\n",
    "    'percentile': '百分位数方法'\n",
    "}\n",
    "\n",
    "# 缺失值处理方法\n",
    "MISSING_METHODS = {\n",
    "    'drop': '删除缺失值',\n",
    "    'mean': '均值填充',\n",
    "    'median': '中位数填充',\n",
    "    'mode': '众数填充',\n",
    "    'forward_fill': '前向填充',\n",
    "    'backward_fill': '后向填充',\n",
    "    'interpolate': '线性插值',\n",
    "    'knn': 'KNN填充'\n",
    "}\n",
    "\n",
    "# 创建输出目录\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载和探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_files(data_path):\n",
    "    \"\"\"加载数据文件\"\"\"\n",
    "    file_patterns = ['*.csv', '*.xlsx', '*.xls']\n",
    "    data_files = []\n",
    "    \n",
    "    for pattern in file_patterns:\n",
    "        files = glob.glob(os.path.join(data_path, pattern))\n",
    "        data_files.extend(files)\n",
    "    \n",
    "    print(f\"找到 {len(data_files)} 个数据文件:\")\n",
    "    for file in data_files:\n",
    "        print(f\"  - {os.path.basename(file)}\")\n",
    "    \n",
    "    return data_files\n",
    "\n",
    "# 加载数据文件\n",
    "data_files = load_data_files(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_file(file_path):\n",
    "    \"\"\"加载单个数据文件\"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif file_path.endswith(('.xlsx', '.xls')):\n",
    "            df = pd.read_excel(file_path)\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的文件格式: {file_path}\")\n",
    "        \n",
    "        print(f\"成功加载文件: {os.path.basename(file_path)}\")\n",
    "        print(f\"数据形状: {df.shape}\")\n",
    "        print(f\"列名: {list(df.columns)}\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"加载文件失败 {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# 示例：加载第一个文件\n",
    "if data_files:\n",
    "    sample_df = load_single_file(data_files[0])\n",
    "    if sample_df is not None:\n",
    "        display(sample_df.head())\n",
    "        display(sample_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 异常值检测和处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(data, factor=1.5):\n",
    "    \"\"\"使用IQR方法检测异常值\"\"\"\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - factor * IQR\n",
    "    upper_bound = Q3 + factor * IQR\n",
    "    return (data < lower_bound) | (data > upper_bound)\n",
    "\n",
    "def detect_outliers_zscore(data, threshold=3):\n",
    "    \"\"\"使用Z-score方法检测异常值\"\"\"\n",
    "    z_scores = np.abs(stats.zscore(data, nan_policy='omit'))\n",
    "    return z_scores > threshold\n",
    "\n",
    "def detect_outliers_percentile(data, lower_percentile=1, upper_percentile=99):\n",
    "    \"\"\"使用百分位数方法检测异常值\"\"\"\n",
    "    lower_bound = data.quantile(lower_percentile/100)\n",
    "    upper_bound = data.quantile(upper_percentile/100)\n",
    "    return (data < lower_bound) | (data > upper_bound)\n",
    "\n",
    "def detect_outliers_isolation_forest(data, contamination=0.1):\n",
    "    \"\"\"使用孤立森林检测异常值\"\"\"\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    \n",
    "    # 处理缺失值\n",
    "    data_clean = data.dropna()\n",
    "    if len(data_clean) == 0:\n",
    "        return pd.Series([False] * len(data), index=data.index)\n",
    "    \n",
    "    iso_forest = IsolationForest(contamination=contamination, random_state=42)\n",
    "    outliers = iso_forest.fit_predict(data_clean.values.reshape(-1, 1))\n",
    "    \n",
    "    # 创建完整的异常值标记\n",
    "    result = pd.Series([False] * len(data), index=data.index)\n",
    "    result.loc[data_clean.index] = outliers == -1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 缺失值处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, method='mean', columns=None):\n",
    "    \"\"\"处理缺失值\"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    if columns is None:\n",
    "        columns = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        if method == 'drop':\n",
    "            df_processed = df_processed.dropna(subset=[col])\n",
    "        elif method == 'mean':\n",
    "            df_processed[col].fillna(df_processed[col].mean(), inplace=True)\n",
    "        elif method == 'median':\n",
    "            df_processed[col].fillna(df_processed[col].median(), inplace=True)\n",
    "        elif method == 'mode':\n",
    "            mode_val = df_processed[col].mode()\n",
    "            if len(mode_val) > 0:\n",
    "                df_processed[col].fillna(mode_val[0], inplace=True)\n",
    "        elif method == 'forward_fill':\n",
    "            df_processed[col].fillna(method='ffill', inplace=True)\n",
    "        elif method == 'backward_fill':\n",
    "            df_processed[col].fillna(method='bfill', inplace=True)\n",
    "        elif method == 'interpolate':\n",
    "            df_processed[col] = df_processed[col].interpolate(method='linear')\n",
    "        elif method == 'knn':\n",
    "            imputer = KNNImputer(n_neighbors=5)\n",
    "            df_processed[col] = imputer.fit_transform(df_processed[[col]]).flatten()\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df, outlier_method='iqr', missing_method='mean', \n",
    "                     outlier_action='remove', columns=None):\n",
    "    \"\"\"\n",
    "    处理数据框的异常值和缺失值\n",
    "    \n",
    "    参数:\n",
    "    - df: 输入数据框\n",
    "    - outlier_method: 异常值检测方法 ('iqr', 'zscore', 'isolation_forest', 'percentile')\n",
    "    - missing_method: 缺失值处理方法 ('drop', 'mean', 'median', 'mode', 'forward_fill', 'backward_fill', 'interpolate', 'knn')\n",
    "    - outlier_action: 异常值处理动作 ('remove', 'replace_nan', 'cap')\n",
    "    - columns: 要处理的列名列表，None表示处理所有数值列\n",
    "    \"\"\"\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    if columns is None:\n",
    "        columns = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    print(f\"处理列: {list(columns)}\")\n",
    "    print(f\"异常值检测方法: {OUTLIER_METHODS.get(outlier_method, outlier_method)}\")\n",
    "    print(f\"缺失值处理方法: {MISSING_METHODS.get(missing_method, missing_method)}\")\n",
    "    \n",
    "    # 异常值处理\n",
    "    outlier_stats = {}\n",
    "    \n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n处理列: {col}\")\n",
    "        \n",
    "        # 检测异常值\n",
    "        if outlier_method == 'iqr':\n",
    "            outliers = detect_outliers_iqr(df_processed[col])\n",
    "        elif outlier_method == 'zscore':\n",
    "            outliers = detect_outliers_zscore(df_processed[col])\n",
    "        elif outlier_method == 'isolation_forest':\n",
    "            outliers = detect_outliers_isolation_forest(df_processed[col])\n",
    "        elif outlier_method == 'percentile':\n",
    "            outliers = detect_outliers_percentile(df_processed[col])\n",
    "        else:\n",
    "            outliers = pd.Series([False] * len(df_processed), index=df_processed.index)\n",
    "        \n",
    "        outlier_count = outliers.sum()\n",
    "        outlier_stats[col] = outlier_count\n",
    "        print(f\"  检测到 {outlier_count} 个异常值\")\n",
    "        \n",
    "        # 处理异常值\n",
    "        if outlier_action == 'remove':\n",
    "            df_processed = df_processed[~outliers]\n",
    "        elif outlier_action == 'replace_nan':\n",
    "            df_processed.loc[outliers, col] = np.nan\n",
    "        elif outlier_action == 'cap':\n",
    "            Q1 = df_processed[col].quantile(0.25)\n",
    "            Q3 = df_processed[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            df_processed[col] = df_processed[col].clip(lower_bound, upper_bound)\n",
    "    \n",
    "    # 缺失值处理\n",
    "    missing_before = df_processed.isnull().sum()\n",
    "    df_processed = handle_missing_values(df_processed, missing_method, columns)\n",
    "    missing_after = df_processed.isnull().sum()\n",
    "    \n",
    "    print(\"\\n=== 处理结果 ===\")\n",
    "    print(f\"原始数据形状: {df.shape}\")\n",
    "    print(f\"处理后数据形状: {df_processed.shape}\")\n",
    "    print(f\"异常值统计: {outlier_stats}\")\n",
    "    print(f\"缺失值处理前: {missing_before.sum()}\")\n",
    "    print(f\"缺失值处理后: {missing_after.sum()}\")\n",
    "    \n",
    "    return df_processed, outlier_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据可视化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data_quality(df, title=\"数据质量分析\"):\n",
    "    \"\"\"可视化数据质量\"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    if len(numeric_cols) == 0:\n",
    "        print(\"没有数值列可以可视化\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    # 缺失值热图\n",
    "    sns.heatmap(df[numeric_cols].isnull(), cbar=True, ax=axes[0,0])\n",
    "    axes[0,0].set_title('缺失值分布')\n",
    "    \n",
    "    # 缺失值统计\n",
    "    missing_counts = df[numeric_cols].isnull().sum()\n",
    "    missing_counts = missing_counts[missing_counts > 0]\n",
    "    if len(missing_counts) > 0:\n",
    "        missing_counts.plot(kind='bar', ax=axes[0,1])\n",
    "        axes[0,1].set_title('各列缺失值数量')\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    else:\n",
    "        axes[0,1].text(0.5, 0.5, '无缺失值', ha='center', va='center', transform=axes[0,1].transAxes)\n",
    "        axes[0,1].set_title('各列缺失值数量')\n",
    "    \n",
    "    # 数据分布（选择前几列）\n",
    "    cols_to_plot = numeric_cols[:min(4, len(numeric_cols))]\n",
    "    for i, col in enumerate(cols_to_plot):\n",
    "        if i < 2:\n",
    "            df[col].hist(bins=30, ax=axes[1,i], alpha=0.7)\n",
    "            axes[1,i].set_title(f'{col} 分布')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compare_before_after(df_before, df_after, column):\n",
    "    \"\"\"比较处理前后的数据\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # 处理前\n",
    "    df_before[column].hist(bins=30, ax=axes[0], alpha=0.7, color='red')\n",
    "    axes[0].set_title(f'{column} - 处理前')\n",
    "    axes[0].axvline(df_before[column].mean(), color='black', linestyle='--', label='均值')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # 处理后\n",
    "    df_after[column].hist(bins=30, ax=axes[1], alpha=0.7, color='green')\n",
    "    axes[1].set_title(f'{column} - 处理后')\n",
    "    axes[1].axvline(df_after[column].mean(), color='black', linestyle='--', label='均值')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批量处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_files(data_files, outlier_method='iqr', missing_method='mean', \n",
    "                       outlier_action='remove', save_results=True):\n",
    "    \"\"\"\n",
    "    批量处理多个数据文件\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for file_path in data_files:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"处理文件: {os.path.basename(file_path)}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # 加载数据\n",
    "        df = load_single_file(file_path)\n",
    "        if df is None:\n",
    "            continue\n",
    "        \n",
    "        # 显示原始数据质量\n",
    "        print(\"\\n原始数据质量:\")\n",
    "        visualize_data_quality(df, f\"原始数据 - {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # 处理数据\n",
    "        df_processed, outlier_stats = process_dataframe(\n",
    "            df, outlier_method, missing_method, outlier_action\n",
    "        )\n",
    "        \n",
    "        # 显示处理后数据质量\n",
    "        print(\"\\n处理后数据质量:\")\n",
    "        visualize_data_quality(df_processed, f\"处理后数据 - {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # 保存结果\n",
    "        if save_results:\n",
    "            output_file = os.path.join(OUTPUT_PATH, f\"processed_{os.path.basename(file_path)}\")\n",
    "            if output_file.endswith(('.xlsx', '.xls')):\n",
    "                output_file = output_file.rsplit('.', 1)[0] + '.csv'\n",
    "            \n",
    "            df_processed.to_csv(output_file, index=False)\n",
    "            print(f\"\\n结果已保存到: {output_file}\")\n",
    "        \n",
    "        results[os.path.basename(file_path)] = {\n",
    "            'original_shape': df.shape,\n",
    "            'processed_shape': df_processed.shape,\n",
    "            'outlier_stats': outlier_stats,\n",
    "            'missing_before': df.isnull().sum().sum(),\n",
    "            'missing_after': df_processed.isnull().sum().sum()\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置处理参数\n",
    "OUTLIER_METHOD = 'iqr'  # 可选: 'iqr', 'zscore', 'isolation_forest', 'percentile'\n",
    "MISSING_METHOD = 'mean'  # 可选: 'drop', 'mean', 'median', 'mode', 'forward_fill', 'backward_fill', 'interpolate', 'knn'\n",
    "OUTLIER_ACTION = 'replace_nan'  # 可选: 'remove', 'replace_nan', 'cap'\n",
    "\n",
    "print(f\"异常值检测方法: {OUTLIER_METHODS.get(OUTLIER_METHOD)}\")\n",
    "print(f\"缺失值处理方法: {MISSING_METHODS.get(MISSING_METHOD)}\")\n",
    "print(f\"异常值处理动作: {OUTLIER_ACTION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量处理所有文件\n",
    "if data_files:\n",
    "    results = batch_process_files(\n",
    "        data_files, \n",
    "        outlier_method=OUTLIER_METHOD,\n",
    "        missing_method=MISSING_METHOD,\n",
    "        outlier_action=OUTLIER_ACTION,\n",
    "        save_results=True\n",
    "    )\n",
    "    \n",
    "    # 显示处理结果摘要\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"处理结果摘要\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for filename, stats in results.items():\n",
    "        print(f\"\\n文件: {filename}\")\n",
    "        print(f\"  原始形状: {stats['original_shape']}\")\n",
    "        print(f\"  处理后形状: {stats['processed_shape']}\")\n",
    "        print(f\"  异常值统计: {stats['outlier_stats']}\")\n",
    "        print(f\"  缺失值: {stats['missing_before']} -> {stats['missing_after']}\")\n",
    "else:\n",
    "    print(\"未找到数据文件，请检查路径设置\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单文件处理示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果需要单独处理某个文件，可以使用以下代码\n",
    "# 替换为您要处理的具体文件路径\n",
    "SINGLE_FILE_PATH = None  # 例如: '../dataset/B题因子库/your_file.csv'\n",
    "\n",
    "if SINGLE_FILE_PATH and os.path.exists(SINGLE_FILE_PATH):\n",
    "    print(f\"处理单个文件: {SINGLE_FILE_PATH}\")\n",
    "    \n",
    "    # 加载数据\n",
    "    df = load_single_file(SINGLE_FILE_PATH)\n",
    "    \n",
    "    if df is not None:\n",
    "        # 显示原始数据信息\n",
    "        print(\"\\n原始数据信息:\")\n",
    "        display(df.describe())\n",
    "        \n",
    "        # 处理数据\n",
    "        df_processed, outlier_stats = process_dataframe(\n",
    "            df, \n",
    "            outlier_method='iqr',\n",
    "            missing_method='mean',\n",
    "            outlier_action='replace_nan'\n",
    "        )\n",
    "        \n",
    "        # 显示处理后数据信息\n",
    "        print(\"\\n处理后数据信息:\")\n",
    "        display(df_processed.describe())\n",
    "        \n",
    "        # 比较处理前后（选择一个数值列）\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            compare_before_after(df, df_processed, numeric_cols[0])\n",
    "else:\n",
    "    print(\"请设置SINGLE_FILE_PATH变量来处理单个文件\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
