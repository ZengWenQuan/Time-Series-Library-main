import torch
import numpy as np
from models.regression.SFFTDualBranchNet import Model

# åˆ›å»ºä¸€ä¸ªç®€å•çš„é…ç½®ç±»
class Config:
    def __init__(self):
        self.feature_size = 1024  # è¾“å…¥åºåˆ—é•¿åº¦
        self.label_size = 3       # è¾“å‡ºæ ‡ç­¾æ•°é‡

# æµ‹è¯•æ¨¡å‹
def test_sfft_model():
    print("å¼€å§‹æµ‹è¯•SFFTDualBranchNetæ¨¡å‹...")
    
    # åˆ›å»ºé…ç½®
    config = Config()
    
    # åˆ›å»ºæ¨¡å‹
    try:
        model = Model(config)
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"  - è¾“å…¥ç‰¹å¾å¤§å°: {config.feature_size}")
        print(f"  - è¾“å‡ºæ ‡ç­¾å¤§å°: {config.label_size}")
    except Exception as e:
        print(f"âœ— æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return
    
    # è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"  - æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"  - å¯è®­ç»ƒå‚æ•°æ•°é‡: {trainable_params:,}")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 4
    test_input = torch.randn(batch_size, config.feature_size)
    
    print(f"\næµ‹è¯•å‰å‘ä¼ æ’­...")
    print(f"  - è¾“å…¥å½¢çŠ¶: {test_input.shape}")
    
    # å‰å‘ä¼ æ’­æµ‹è¯•
    try:
        model.eval()
        with torch.no_grad():
            output = model(test_input)
        print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"  - è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"  - è¾“å‡ºèŒƒå›´: [{output.min().item():.4f}, {output.max().item():.4f}]")
    except Exception as e:
        print(f"âœ— å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•æ¢¯åº¦è®¡ç®—
    print(f"\næµ‹è¯•åå‘ä¼ æ’­...")
    try:
        model.train()
        output = model(test_input)
        loss = torch.mean(output ** 2)  # ç®€å•çš„æŸå¤±å‡½æ•°
        loss.backward()
        print(f"âœ“ åå‘ä¼ æ’­æˆåŠŸ")
        print(f"  - æŸå¤±å€¼: {loss.item():.6f}")
        
        # æ£€æŸ¥æ¢¯åº¦
        grad_norm = 0
        for param in model.parameters():
            if param.grad is not None:
                grad_norm += param.grad.data.norm(2).item() ** 2
        grad_norm = grad_norm ** 0.5
        print(f"  - æ¢¯åº¦èŒƒæ•°: {grad_norm:.6f}")
    except Exception as e:
        print(f"âœ— åå‘ä¼ æ’­å¤±è´¥: {e}")
        return
    
    print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¨¡å‹å¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
    
    # æ‰“å°æ¨¡å‹ç»“æ„æ¦‚è§ˆ
    print(f"\næ¨¡å‹ç»“æ„æ¦‚è§ˆ:")
    print(f"  1. SFFTç‰¹å¾æå–å™¨")
    print(f"  2. å…¨å·ç§¯åˆ†æ”¯ (5å±‚å·ç§¯+æ± åŒ–)")
    print(f"  3. Inceptionåˆ†æ”¯ (5å±‚å¤šæ ¸å·ç§¯+æ± åŒ–)")
    print(f"  4. ç‰¹å¾èåˆä¸FFNè¾“å‡º")

if __name__ == "__main__":
    test_sfft_model()