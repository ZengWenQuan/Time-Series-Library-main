# FreqInceptionNet 配置文件 (v2, 标准化结构)

# --- 分支、融合与头模块选择 ---
global_branch_name: 'FrequencyBranch'
local_branch_name: 'InceptionBranch'
fusion_name: 'GeneralFusion'
head_name: 'SimpleLSTM_FFN_Head'

# --- 分支参数配置 ---
continuum_branch_config:
  use_batch_norm: true
  dropout: 0.2
  # feature_size will be added dynamically by the model
  conv_layers:
    - {out_channels: 16, kernel_size: 7, stride: 2, padding: 3}
    - {out_channels: 32, kernel_size: 5, stride: 2, padding: 2}
    - {out_channels: 64, kernel_size: 3, stride: 2, padding: 1}
  mlp_output_dim: 256

normalized_branch_config:
  use_batch_norm: true
  blocks:
    - out_channels_per_path: {3: 16, 5: 16, 7: 16}
      channel_attention_reduction: 8
      use_pooling: true
      pool_size: 2
    - out_channels_per_path: {3: 32, 5: 32, 9: 32}
      channel_attention_reduction: 16
      use_pooling: true
      pool_size: 2
    - out_channels_per_path: {3: 64, 5: 64, 11: 64}
      channel_attention_reduction: 16
      use_pooling: true
      pool_size: 2
    - out_channels_per_path: {3: 96, 5: 96}
      channel_attention_reduction: 16
      use_pooling: false
      pool_size: 2

# --- 融合模块参数配置 ---
fusion_config:
  strategy: 'concat'
  # dim_norm and dim_cont will be added dynamically by the model

# --- 头模块参数配置 ---
head_config:
  # lstm_input_dim will be added dynamically by the model
  lstm_hidden_dim: 256
  lstm_layers: 2
  lstm_dropout: 0.2
  ffn_hidden_dims: [512, 256]
  dropout: 0.3
  use_batch_norm: true
