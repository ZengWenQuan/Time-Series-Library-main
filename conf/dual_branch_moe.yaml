
# DualBranchMoENet 配置文件

# --- 训练设置 ---
training_settings:
  loss_function: 'mse' # 可选: mse, mae, l1, l2, RegressionFocalLoss

# --- 模型参数 ---

normalization_type: "batchnorm" # 可选: "batchnorm", "layernorm", "none"

freq_branch:
  fft:
    n_fft: 512
    hop_length: 128
  moe:
    num_experts: 8
    k: 2
    gating_hidden_dim: 64
  expert_pyramid:
    - {in_channels: 257, out_channels: 32, kernel_size: 3, pool_size: 2}
    - {in_channels: 32, out_channels: 64, kernel_size: 3, pool_size: 2}

line_branch:
  pyramid_with_attention:
    - {in_channels: 1, out_channels: 32, kernel_size: 5, pool_size: 2, se_reduction: 4}
    - {in_channels: 32, out_channels: 64, kernel_size: 3, pool_size: 2, se_reduction: 8}
    - {in_channels: 64, out_channels: 128, kernel_size: 3, pool_size: 2, se_reduction: 16}

fusion_module:
  lstm_hidden_dim: 128
  lstm_layers: 2
  bidirectional: True
  dropout_rate: 0.2
  ffn:
    - {in_features: 256, out_features: 128}
    - {in_features: 128, out_features: 64}
    - {in_features: 64, out_features: 4, is_output_layer: True}
