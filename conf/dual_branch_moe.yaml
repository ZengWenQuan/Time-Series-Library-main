# DualBranchMoENet 配置文件 (v4, 使用分支、融合和头注册机制)

# --- 分支、融合与头模块选择 ---
global_branch_name: 'FrequencyMoEBranch'
local_branch_name: 'LineAttentionBranch'
fusion_name: 'GeneralFusion'
head_name: 'LSTM_FFN_Head'

# --- 分支参数配置 ---
continuum_branch_config:
  fft:
    n_fft: 512
    hop_length: 128
  moe:
    num_experts: 8
    k: 2
    gating_hidden_dim: 64
  expert_pyramid:
    - {in_channels: 257, out_channels: 32, kernel_size: 3, pool_size: 2}
    - {in_channels: 32, out_channels: 64, kernel_size: 3, pool_size: 2}

normalized_branch_config:
  pyramid_with_attention:
    - {out_channels: 32, kernel_size: 5, pool_size: 2, se_reduction: 4}
    - {out_channels: 64, kernel_size: 3, pool_size: 2, se_reduction: 8}
    - {out_channels: 128, kernel_size: 3, pool_size: 2, se_reduction: 16}

# --- 融合模块参数配置 ---
fusion_config:
  strategy: 'concat'
  # dim_norm and dim_cont will be added dynamically by the model

# --- 头模块参数配置 ---
head_config:
  # head_input_dim will be added dynamically by the model
  lstm_hidden_dim: 128
  lstm_layers: 2
  dropout: 0.2
  prediction_head:
    hidden_layers: [128, 64]

# --- 通用设置 ---
normalization_type: "batchnorm"

training_settings:
  loss_function: 'mse'
  loss_weights: [1.0, 1.0, 1.0, 1.0]
  lradj: 'cos'
  targets: ['Teff', 'logg', 'FeH', 'CFe']
  mixed_precision: True