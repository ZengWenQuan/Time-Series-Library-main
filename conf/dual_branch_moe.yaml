# DualBranchMoENet 配置文件 (v2, 使用分支注册机制)

# --- 训练设置 ---
training_settings:
  loss_function: 'mse'
  mixed_precision: True

# --- 分支选择 ---
continuum_branch_name: 'FrequencyMoEBranch'
normalized_branch_name: 'LineAttentionBranch'

# --- 分支参数配置 ---
continuum_branch_config:
  fft:
    n_fft: 512
    hop_length: 128
  moe:
    num_experts: 8
    k: 2
    gating_hidden_dim: 64
  expert_pyramid:
    - {in_channels: 257, out_channels: 32, kernel_size: 3, pool_size: 2}
    - {in_channels: 32, out_channels: 64, kernel_size: 3, pool_size: 2}

normalized_branch_config:
  pyramid_with_attention:
    - {out_channels: 32, kernel_size: 5, pool_size: 2, se_reduction: 4}
    - {out_channels: 64, kernel_size: 3, pool_size: 2, se_reduction: 8}
    - {out_channels: 128, kernel_size: 3, pool_size: 2, se_reduction: 16}

# --- 融合与预测头配置 ---
fusion_module_config:
  lstm_hidden_dim: 128
  lstm_layers: 2
  dropout_rate: 0.2
  ffn:
    - {out_features: 128}
    - {out_features: 64}
    - {out_features: 4, is_output_layer: True}

# --- 通用设置 ---
normalization_type: "batchnorm"