d_model: 128
n_heads: 8
d_ff: 512
dropout: 0.1
activation: 'relu'
num_layers: 2